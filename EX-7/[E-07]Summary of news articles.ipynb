{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[E-07]Summary of news articles.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 0. 사용할 라이브러리 불러오기"
      ],
      "metadata": {
        "id": "C_xFv3Cy5BS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install summa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h39tZ76N6wQ2",
        "outputId": "ca6e8755-a2ad-4abf-cdcd-4cc3d9301d1a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting summa\n",
            "  Downloading summa-1.2.0.tar.gz (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.7/dist-packages (from summa) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy>=0.19->summa) (1.21.6)\n",
            "Building wheels for collected packages: summa\n",
            "  Building wheel for summa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for summa: filename=summa-1.2.0-py3-none-any.whl size=54412 sha256=1a549b8852a2e22d7585ddb9409857e9cd52de306ec4ee5c89e2bc8403ce68a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/64/ac/7b443477588d365ef37ada30d456bdf5f07dc5be9f6324cb6e\n",
            "Successfully built summa\n",
            "Installing collected packages: summa\n",
            "Successfully installed summa-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " summa가 깔려있지 않으니 새로 인스톨해줍니다."
      ],
      "metadata": {
        "id": "VChy4bih8Tic"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BukRzl0V40ai",
        "outputId": "ce0c5051-3d7b-45ea-9c39-f69421f91938"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords #상기 3개의 nltk는 불용어처리용\n",
        "import tensorflow as tf\n",
        "import summa\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from bs4 import BeautifulSoup \n",
        "from tensorflow.keras.preprocessing.text import Tokenizer \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import urllib.request\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.layers import AdditiveAttention"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 데이터 불러오기"
      ],
      "metadata": {
        "id": "oV_LJGyo_Fev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
        "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
      ],
      "metadata": {
        "id": "uqXn-Jsr5cU-"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "github url을 통해 바로 data 다운로드 없이 온라인상으로 저장했습니다. "
      ],
      "metadata": {
        "id": "CfFJkwZE8auy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "K2NPcsHY6gVd",
        "outputId": "ceb7a5ce-7790-48a0-e1b0-036ad8bbf35a"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               headlines  \\\n",
              "37889  Man takes Ã¢ÂÂ¹15-lakh loan to screen World C...   \n",
              "46891  2,000-year-old Roman 'boxing gloves' dug out i...   \n",
              "31235  I hope I don't trip and fall on red carpet at ...   \n",
              "74223     Neymar dribbles past 5 defenders to score goal   \n",
              "74426  No nepotism as RK Studios isn't launching me, ...   \n",
              "35882  Court rules farting isn't bullying, dismisses ...   \n",
              "38527  Bhaiyyuji Maharaj leaves all property to his s...   \n",
              "75785  Delhi institute rolls back 'biased' hostel tim...   \n",
              "13787  Buffalo meat wrongly printed as beef in Mumbai...   \n",
              "39095  2 men lynched after being mistaken as kidnappe...   \n",
              "\n",
              "                                                    text  \n",
              "37889  A football fan in Assam took a bank loan of Ã¢...  \n",
              "46891  UK-based researchers have uncovered Roman \"box...  \n",
              "31235  Pakistani actress Mahira Khan, who will make h...  \n",
              "74223  World's most expensive footballer Neymar, maki...  \n",
              "74426  Aadar Jain has said he is not a product of nep...  \n",
              "35882  A construction firm employee has lost a $1.8 m...  \n",
              "38527  The police have recovered the second page of s...  \n",
              "75785  Delhi Technological University has tentatively...  \n",
              "13787  An advertisement by the Brihanmumbai Municipal...  \n",
              "39095  Two men were lynched in Assam's Karbi Anglong ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4907b33f-b14c-4de2-b480-779e8fbb1052\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headlines</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>37889</th>\n",
              "      <td>Man takes Ã¢ÂÂ¹15-lakh loan to screen World C...</td>\n",
              "      <td>A football fan in Assam took a bank loan of Ã¢...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46891</th>\n",
              "      <td>2,000-year-old Roman 'boxing gloves' dug out i...</td>\n",
              "      <td>UK-based researchers have uncovered Roman \"box...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31235</th>\n",
              "      <td>I hope I don't trip and fall on red carpet at ...</td>\n",
              "      <td>Pakistani actress Mahira Khan, who will make h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74223</th>\n",
              "      <td>Neymar dribbles past 5 defenders to score goal</td>\n",
              "      <td>World's most expensive footballer Neymar, maki...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74426</th>\n",
              "      <td>No nepotism as RK Studios isn't launching me, ...</td>\n",
              "      <td>Aadar Jain has said he is not a product of nep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35882</th>\n",
              "      <td>Court rules farting isn't bullying, dismisses ...</td>\n",
              "      <td>A construction firm employee has lost a $1.8 m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38527</th>\n",
              "      <td>Bhaiyyuji Maharaj leaves all property to his s...</td>\n",
              "      <td>The police have recovered the second page of s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75785</th>\n",
              "      <td>Delhi institute rolls back 'biased' hostel tim...</td>\n",
              "      <td>Delhi Technological University has tentatively...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13787</th>\n",
              "      <td>Buffalo meat wrongly printed as beef in Mumbai...</td>\n",
              "      <td>An advertisement by the Brihanmumbai Municipal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39095</th>\n",
              "      <td>2 men lynched after being mistaken as kidnappe...</td>\n",
              "      <td>Two men were lynched in Assam's Karbi Anglong ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4907b33f-b14c-4de2-b480-779e8fbb1052')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4907b33f-b14c-4de2-b480-779e8fbb1052 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4907b33f-b14c-4de2-b480-779e8fbb1052');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "앞서 아마존 리뷰처럼 text 부분과 summary(headline)부분 으로 나눠져 있으니, 인코더/디코더로 나눠서 진행하면 될 것 같습니다!  \n",
        "총 몇 개가 있는지 확인해볼까요"
      ],
      "metadata": {
        "id": "WsVVfE4h-b2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('전체 샘플수 :', (len(data)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvvMBCg_8OCl",
        "outputId": "d7a23acc-c809-462d-c124-6cb029f4df9f"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플수 : 98401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['text'])\n",
        "print(data['headlines'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYV1i3al_T_s",
        "outputId": "d1a0dbfe-470d-4697-f737-d5a75fef2deb"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        Saurav Kant, an alumnus of upGrad and IIIT-B's...\n",
            "1        Kunal Shah's credit card bill payment platform...\n",
            "2        New Zealand defeated India by 8 wickets in the...\n",
            "3        With Aegon Life iTerm Insurance plan, customer...\n",
            "4        Speaking about the sexual harassment allegatio...\n",
            "                               ...                        \n",
            "98396    A CRPF jawan was on Tuesday axed to death with...\n",
            "98397    'Uff Yeh', the first song from the Sonakshi Si...\n",
            "98398    According to reports, a new version of the 199...\n",
            "98399    A new music video shows rapper Snoop Dogg aimi...\n",
            "98400    Madhesi Morcha, an alliance of seven political...\n",
            "Name: text, Length: 98401, dtype: object\n",
            "0        upGrad learner switches to career in ML & Al w...\n",
            "1        Delhi techie wins free food from Swiggy for on...\n",
            "2        New Zealand end Rohit Sharma-led India's 12-ma...\n",
            "3        Aegon life iTerm insurance plan helps customer...\n",
            "4        Have known Hirani for yrs, what if MeToo claim...\n",
            "                               ...                        \n",
            "98396    CRPF jawan axed to death by Maoists in Chhatti...\n",
            "98397    First song from Sonakshi Sinha's 'Noor' titled...\n",
            "98398           'The Matrix' film to get a reboot: Reports\n",
            "98399    Snoop Dogg aims gun at clown dressed as Trump ...\n",
            "98400    Madhesi Morcha withdraws support to Nepalese g...\n",
            "Name: headlines, Length: 98401, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "각 열로 잘 나눠져 있고, 갯수는 98,401개로 약 10만개정도 있으니 데이터 삭제없이 전처리를 진행하도록 합니다.  "
      ],
      "metadata": {
        "id": "Rt94EJiQ-1Kl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 데이터 전처리(추상적 요약)\n",
        "\n",
        "### 1) 중복 샘플 및 Null 값 제거  \n",
        "\n",
        "먼저 혹시 모를 중복 및 null 값을 제거해주도록 합니다."
      ],
      "metadata": {
        "id": "k1uhQjWN_C06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
        "print('Headlines 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jZbktz7-zYr",
        "outputId": "612e16bb-b536-426c-e5f3-1eea56ca3da4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 열에서 중복을 배제한 유일한 샘플의 수 : 98360\n",
            "Headlines 열에서 중복을 배제한 유일한 샘플의 수 : 98280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hedlines_overlap = data[data['headlines'].duplicated()]\n",
        "print(hedlines_overlap['headlines'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxG47gKuCsik",
        "outputId": "802ed292-f4b7-4508-bfd3-88638765759a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3292     Isha Ambani features on February cover of Vogu...\n",
            "3293     Indian Oil looking for annual deal to buy crud...\n",
            "32850    David Beckham once scored a 60-yard goal from ...\n",
            "34227    Sachin once fielded for Pakistan before making...\n",
            "34518      Iraq launches air strikes against ISIS in Syria\n",
            "                               ...                        \n",
            "95135    Parveen Babi was 1st Indian film star on TIME ...\n",
            "95473    Sachin had not let Sehwag watch 2011 World Cup...\n",
            "95670    How did the tradition of April Fools' Day orig...\n",
            "96540    Sachin first opened in ODIs due to Sidhu's 'st...\n",
            "97489              Who are the richest women in the world?\n",
            "Name: headlines, Length: 121, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "역시 기존 98,401개와 다른 숫자를 출력하고 있습니다.  \n",
        "왜 text와 headlines의 중복제외 숫자가 다른지는 의문입니다...만....  \n",
        "headlines 중복 데이터 121개를 실제 데이터에서 찾아보니, headlines가 겹치면 text도 중복이라는 것을 확인했습니다. 그럼 먼저 headlines의 중복데이터를 `drop_duplicates()`로 지우고 다시 text의 중복데이터를 확인해봅니다.  "
      ],
      "metadata": {
        "id": "-N8G2OyM_y6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop_duplicates(subset = ['headlines'], inplace=True)"
      ],
      "metadata": {
        "id": "n8_gNma0_pwY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('전체 샘플수 :', (len(data)))\n",
        "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
        "print('Headlines 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9CSXCddJ50v",
        "outputId": "598d40fe-3619-40d3-d8f6-a43b67127c94"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플수 : 98280\n",
            "Text 열에서 중복을 배제한 유일한 샘플의 수 : 98262\n",
            "Headlines 열에서 중복을 배제한 유일한 샘플의 수 : 98280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "text가 같은데 headlines가 다르다...?  \n",
        "이걸 중복으로 봐야할까...? 같은 문장에서 다른 서머리를 뽑아낼 수도 있는거 아닐까?  \n",
        "\n",
        "한번 실제 데이터를 확인해보자."
      ],
      "metadata": {
        "id": "hKh8Rqr7KFZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_overlap = data[data['text'].duplicated()]\n",
        "print(text_overlap['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSzS0-tFJqc1",
        "outputId": "d5f519f7-b7c0-4d2c-b167-837b48a4d856"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20754    Safeguard yourself against life's unpleasant s...\n",
            "44594    Berger Paints has launched Berger Express Pain...\n",
            "52021    Australia's Anthony Stuart took a hat-trick in...\n",
            "53578    Former Windies' captain Brian Lara named his f...\n",
            "53865    Cricket legend Don Bradman reversed the Austra...\n",
            "53892    German Formula One legend Michael Schumacher, ...\n",
            "54078    Former Australian leg-spinner Shane Warne was ...\n",
            "55208    During an El ClÃÂ¡sico match in 2002, Barcelo...\n",
            "57402    Virender Sehwag was captaining India when he h...\n",
            "58715    The first-ever official international football...\n",
            "58934    Windies' Gus Logie was adjudged Man of the Mat...\n",
            "61055    The first wicket and first catch in Test crick...\n",
            "61445    Former Australian fast bowler Glenn McGrath, w...\n",
            "62639    Former batsman Sachin Tendulkar became the fir...\n",
            "62785    India conceded an ODI against Pakistan on Nove...\n",
            "78519    A TechCrunch report has claimed that IndiaÃ¢Â...\n",
            "80355    As many as 54,250 fluorescent-yellow tennis ba...\n",
            "84724    Australia won the 1999 Cricket World Cup after...\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Berger Express Painting introduces fast and dust-free home painting\"  \n",
        "\"Berger introduces T20 of painting with Express Painting\"\n",
        "등 **같은 내용이지만 summary를 다르게 한 데이터**들을 보니, 이것도 좋은 소스가 되지 않을까 싶다.  \n",
        "(오히려 더 헷갈리려나..?)  \n",
        "\n",
        "---\n",
        "\n",
        "이런걸 **이상치**라고함. 과적합을 줄이기 위해서 이런 노이즈를 일부러 줄 수도있지만, 학습단계에서는 거의 안한다고 한다.  \n",
        "그럼 지워야겠다...^_^..... 지워주자!"
      ],
      "metadata": {
        "id": "8R45oSvULd6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop_duplicates(subset = ['text'], inplace=True)"
      ],
      "metadata": {
        "id": "vW0SaqnLKfbF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('전체 샘플수 :', (len(data)))\n",
        "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
        "print('Headlines 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4GX5tnFLOin",
        "outputId": "6e17f779-6499-49c6-824a-6c8828121298"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플수 : 98262\n",
            "Text 열에서 중복을 배제한 유일한 샘플의 수 : 98262\n",
            "Headlines 열에서 중복을 배제한 유일한 샘플의 수 : 98262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "샘플수와 text, headlines의 수가 같아져 중복값이 없는 것을 확인할 수 있다.  \n",
        "\n",
        "그리고 있을지 모른 null값을 확인하고 제거해주자."
      ],
      "metadata": {
        "id": "6ZYZNJfkNprR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rsuuz3YINo7p",
        "outputId": "1c359dda-641c-4528-994e-386963d6895b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "headlines    0\n",
              "text         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "중복값, null값 모두 없는 것을 확인했다.  \n",
        "이제 텍스트 정규화 및 불용어를 제거해주자."
      ],
      "metadata": {
        "id": "FnzfqtU8N0PJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 텍스트 정규화 & 불용어 제거  \n",
        "\n",
        "데이터가 영문이니 I'll -> I will 처럼 영문에 맞는 정규화 처리를 해주자.  \n",
        "(이전 실습 데이터 처리에서 이 방법을 알았으면 더 정확한 학습을 하고 데이터를 뽑아낼 수 있지 않을까 아쉬움이 남는다.)"
      ],
      "metadata": {
        "id": "ogP3f3aGclCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\", \"yrs\": \"years\"}\n",
        "\n",
        "print(\"정규화 사전의 수: \", len(contractions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCYAo2wTNyZc",
        "outputId": "f4f89619-7836-48a5-9a42-3dc420a28d54"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정규화 사전의 수:  121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "정규화 준비를 마쳤으니, NLTK의 stopwors를 사용하여 불용어 처리를 해주자."
      ],
      "metadata": {
        "id": "hKmBt4k_dEzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('불용어 개수 :', len(stopwords.words('english') ))\n",
        "print(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2MlLqagdB6p",
        "outputId": "35a49c98-0aff-4a77-e175-8c4a39a788fb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "불용어 개수 : 179\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "정규화 및 불용어 처리준비를 마쳤다.  \n",
        "그리고 이 외에 소문자화, html 태그 제거 등을 전처리 함수를 사용해 적용해주자.  \n",
        "\n",
        "이번 데이터는 뉴스 텍스트 및 헤드라인으로 리뷰처럼 ummmm 같은 일상어는 나올일이 없으니 관련된 re.sub는 제외하고 적용해주자. "
      ],
      "metadata": {
        "id": "9n3yUbdlfkXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리 함수\n",
        "def preprocess_sentence(sentence, remove_stopwords=True):\n",
        "    sentence = sentence.lower() # 텍스트 소문자화\n",
        "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
        "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
        "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
        "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
        "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
        "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
        "    \n",
        "    # 불용어 제거 (Text)\n",
        "    if remove_stopwords:\n",
        "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
        "    # 불용어 미제거 (Summary)\n",
        "    else:\n",
        "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
        "    return tokens\n",
        "print('전처리 함수 준비끝:)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhQNS00QdRCE",
        "outputId": "33a779bd-3b2c-44dc-b431-698546e64dee"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전처리 함수 준비끝:)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "아까 랜덤으로 확인한 데이터에서 â¹ 같이 이상한 내용이 있었는데, 이걸 포함해서 잘 처리되는지 한번 확인해본다."
      ],
      "metadata": {
        "id": "fnUJvTsRgksO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp_text = 'it could save $5 billion (nearly â¹33,500 crore) over next seven years,'\n",
        "\n",
        "print(\"text: \", preprocess_sentence(temp_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuTrbU-5gLYk",
        "outputId": "5390107e-8f71-417b-d830-8516e690683e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text:  could save billion next seven years\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "옥키! 잘 제거되는 것을 확인했다. 역시 능력이 좋구만.  \n",
        "\n",
        "함수가 잘 처리하는것을 보았으니, 훈련데이터 전체에 대해 전처리를 수행하자.  \n",
        "이때, text는 불용어를 제거하고, Headlines의 경우는 불용어를 제거하지 않을 것이니 따로 호출해서 진행하도록 하자. "
      ],
      "metadata": {
        "id": "Bnm9huNwhBFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text = []\n",
        "# 전체 Text 데이터에 대한 전처리\n",
        "for s in data['text']:\n",
        "    clean_text.append(preprocess_sentence(s))\n",
        "\n",
        "# 전처리 후 출력\n",
        "print(\"Text 전처리 후 결과: \", clean_text[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xx9ruYxygyUj",
        "outputId": "5536ce8a-da87-4fb2-9fde-edb363a11248"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 전처리 후 결과:  ['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers', 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit', 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history', 'aegon life iterm insurance plan customers enjoy tax benefits premiums paid save taxes plan provides life cover age years also customers options insure critical illnesses disability accidental death benefit rider life cover age years', 'speaking sexual harassment allegations rajkumar hirani sonam kapoor said known hirani many years true metoo movement get derailed metoo movement always believe woman case need reserve judgment added hirani accused assistant worked sanju']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 headlines에 대해서 전처리 함수를 처리할 땐, 불용어 제거를 수행하지 않는다는 의미에서 두 번째 인자로 False를 넣어주자"
      ],
      "metadata": {
        "id": "9qIdhyrmiFeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clean_headlines = []\n",
        "# 전체 Headlines 데이터에 대한 전처리\n",
        "for s in data['headlines']:\n",
        "    clean_headlines.append(preprocess_sentence(s, False))\n",
        "\n",
        "print(\"Headlines 전처리 후 결과: \", clean_headlines[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGRddfNliCHR",
        "outputId": "3e58598f-0c2a-431e-cca1-638d50571851"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Headlines 전처리 후 결과:  ['upgrad learner switches to career in ml al with salary hike', 'delhi techie wins free food from swiggy for one year on cred', 'new zealand end rohit sharma led india match winning streak', 'aegon life iterm insurance plan helps customers save tax', 'have known hirani for yrs what if metoo claims are not true sonam']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리한 clean_~ 데이터들을 원래 text와 headlines로 넣어주자.  \n",
        "\n",
        "그리고 전처리 후 혹시라도 빈값을 가진 샘플이 있을 수 있으니 null값으로 처리해 지워주자"
      ],
      "metadata": {
        "id": "yM094gJoibqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['text'] = clean_text\n",
        "data['headlines'] = clean_headlines\n",
        "\n",
        "# 빈 값을 Null 값으로 변환\n",
        "data.replace('', np.nan, inplace=True)\n",
        "print('null 처리 완료:)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "XBPgN6psibPY",
        "outputId": "e8e1d6ff-9f15-4583-cf48-64a2b9a3e546"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-5555f29301de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'headlines'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_headlines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 빈 값을 Null 값으로 변환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3610\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3611\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3612\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3614\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3782\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3783\u001b[0m         \"\"\"\n\u001b[0;32m-> 3784\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3786\u001b[0m         if (\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4509\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4510\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         raise ValueError(\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0;34m\"does not match length of index \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Length of values (98262) does not match length of index (98225)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#null 갯수 확인\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N52a0gi8i50u",
        "outputId": "2bf45f1c-353f-43a1-9558-e28372f4a189"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "headlines         0\n",
              "text              0\n",
              "decoder_input     0\n",
              "decoder_target    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Train/Test 데이터 나눠주기\n",
        "\n",
        "---\n",
        "\n",
        "학습에 사용할 데이터 크기를 결정해주고, 문장의 시작과 끝을 표시해주자."
      ],
      "metadata": {
        "id": "jj9GIsjTjCCF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 샘플의 최대 길이 정하기\n",
        "- 샘플들이 최소/최대/평균 길이 및 분포를 확인한다"
      ],
      "metadata": {
        "id": "d3LJKr58jU2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 길이 분포 출력\n",
        "\n",
        "\n",
        "text_len = [len(s.split()) for s in data['text']]\n",
        "headlines_len = [len(s.split()) for s in data['headlines']]\n",
        "\n",
        "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
        "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
        "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
        "print('요약의 최소 길이 : {}'.format(np.min(headlines_len)))\n",
        "print('요약의 최대 길이 : {}'.format(np.max(headlines_len)))\n",
        "print('요약의 평균 길이 : {}'.format(np.mean(headlines_len)))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.boxplot(text_len)\n",
        "plt.title('Text')\n",
        "plt.subplot(1,2,2)\n",
        "plt.boxplot(headlines_len)\n",
        "plt.title('Headlines')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.title('Text')\n",
        "plt.hist(text_len, bins = 40)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()\n",
        "\n",
        "plt.title('Headlines')\n",
        "plt.hist(headlines_len, bins = 40)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 962
        },
        "id": "IbUDQsUyjURQ",
        "outputId": "7d3a4055-1539-466b-b8a0-dc0a5e955906"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "텍스트의 최소 길이 : 1\n",
            "텍스트의 최대 길이 : 60\n",
            "텍스트의 평균 길이 : 35.10029309397326\n",
            "요약의 최소 길이 : 1\n",
            "요약의 최대 길이 : 16\n",
            "요약의 평균 길이 : 9.299444342675704\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text의 경우\n",
        "- 최소 길이: 1\n",
        "- 최대 길이: 60\n",
        "- 평균 길이: 35  \n",
        "시각화된 그래프로 봤을 때, 대체적으로 30~40내외의 길이를 가진다는 것을 확인할 수 있다.\n",
        "\n",
        "Headlines의 경우\n",
        "- 최소 길이: 1\n",
        "- 최대 길이: 16\n",
        "- 평균 길이: 9  \n",
        "시각화된 그래프로 봤을 때, 대체적으로 8~10 내외의 길이를 가지고 있다는 것을 알 수 있다.\n",
        "\n",
        "또한 Headlines의 경우 평균길이가 9로 text 원문이 35인것에 비해 약 4배정도 차이가 나는 것을 알 수 있다. \n",
        "\n",
        "흠... 저 text에서 길이 1짜리가 튀어서 뭔지 확인해보고 싶다..!  "
      ],
      "metadata": {
        "id": "GLGoJ1MBnVOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "curious_data = [idx for idx, val in enumerate(text_len) if val <= 5 ]\n",
        "print(curious_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDY9_LCws3_m",
        "outputId": "9f0a2185-f0d1-4597-9367-a82369e5313d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[52]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.loc[52] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6wNEMnzm17T",
        "outputId": "d074bc6b-15cd-4976-a807-ae3d8f38c223"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "headlines    headlines\n",
              "text              text\n",
              "Name: 52, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "뭐야... headlines은 headlines이고, text는 text다....   \n",
        "기자가 일하기 싫었나...?ㅋㅋㅋ 이 값도 잊지않고 제거해주도록 하고, \n",
        "\n",
        "이제 어느정도 길이를 정해야 샘플을 많이 자르지 않고 담을 수 있는지 확인해보자. \n",
        "\n",
        "우선 임의로 text의 max_len은 50, headlines의 max_len은 14로 정해본다."
      ],
      "metadata": {
        "id": "asIkfwZwuZmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#52번 데이터 삭제\n",
        "data=data.drop([52],axis=0)"
      ],
      "metadata": {
        "id": "xbxsRrBlwpnO"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_max_len = 50\n",
        "headlines_max_len = 14\n",
        "print('max_len 설정 완료')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgfJrGCAqffT",
        "outputId": "acdf78c6-8385-43e3-b525-10ce50e96b23"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_len 설정 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def below_threshold_len(max_len, nested_list):\n",
        "  cnt = 0\n",
        "  for s in nested_list:\n",
        "    if(len(s.split()) <= max_len):\n",
        "        cnt = cnt + 1\n",
        "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))\n",
        "print('max_len별 샘플 비율 함수 설정 완료:)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nScwtnfcvJSC",
        "outputId": "ae764fbb-ac84-4833-bd8b-ab3a1a267273"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_len별 샘플 비율 함수 설정 완료:)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "below_threshold_len(text_max_len, data['text'])\n",
        "below_threshold_len(headlines_max_len, data['headlines'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzbYa-7ivUCy",
        "outputId": "a240969d-3413-4405-eb08-e7ff00cab782"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 중 길이가 50 이하인 샘플의 비율: 0.9998575223130235\n",
            "전체 샘플 중 길이가 14 이하인 샘플의 비율: 0.9997761064918941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "각각 max_len 보다 큰 샘플 비율이 약 1%정도다.  \n",
        "더 잘라내보고 싶지만, 쫄보는 데이터 하나하나가 소중하기때문에... 이대로 진행해본다.\n",
        "\n",
        "---\n",
        "\n",
        "@NLP에서 데이터 처리시 n% 이상은 이상비율로 처리해서 자른다는게 논문이나 자료로 나와있으면 그것에 맞춰서 자르고 싶은데,, 나와있지 않으니 결정하기 어렵다.  \n",
        "정규분포로 따져서 뭐 5%로 자른다 하기엔 정규분포를 따르는게 아니니까...  \n",
        "그래도 어느정도 boxplot에서 크게 벗어난 데이터는 삭제했다는 생각으로 계속 진행해보기로했다."
      ],
      "metadata": {
        "id": "ukWv5ONevm_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[data['text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
        "data = data[data['headlines'].apply(lambda x: len(x.split()) <= headlines_max_len)]\n",
        "print('전체 샘플수 :', (len(data)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1QnnQGXvhlf",
        "outputId": "8ca25917-e227-45cc-d893-687a1fc824de"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플수 : 98225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전체 샘플수 : 98262 -> 98225로 (52번 데이터 포함) 약 37개가 삭제 되었다. "
      ],
      "metadata": {
        "id": "o8o5m2WUxrji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 시작 토큰과 종료 토큰 추가하기"
      ],
      "metadata": {
        "id": "W6xF8WsXzyNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
        "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
        "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CzoakuEWxmEL",
        "outputId": "4e574d9a-f335-46dc-b0c7-5dc5e9726b49"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           headlines  \\\n",
              "0  upgrad learner switches to career in ml al wit...   \n",
              "1  delhi techie wins free food from swiggy for on...   \n",
              "2  new zealand end rohit sharma led india match w...   \n",
              "3  aegon life iterm insurance plan helps customer...   \n",
              "4  have known hirani for yrs what if metoo claims...   \n",
              "\n",
              "                                                text  \\\n",
              "0  saurav kant alumnus upgrad iiit pg program mac...   \n",
              "1  kunal shah credit card bill payment platform c...   \n",
              "2  new zealand defeated india wickets fourth odi ...   \n",
              "3  aegon life iterm insurance plan customers enjo...   \n",
              "4  speaking sexual harassment allegations rajkuma...   \n",
              "\n",
              "                                       decoder_input  \\\n",
              "0  sostoken upgrad learner switches to career in ...   \n",
              "1  sostoken delhi techie wins free food from swig...   \n",
              "2  sostoken new zealand end rohit sharma led indi...   \n",
              "3  sostoken aegon life iterm insurance plan helps...   \n",
              "4  sostoken have known hirani for yrs what if met...   \n",
              "\n",
              "                                      decoder_target  \n",
              "0  upgrad learner switches to career in ml al wit...  \n",
              "1  delhi techie wins free food from swiggy for on...  \n",
              "2  new zealand end rohit sharma led india match w...  \n",
              "3  aegon life iterm insurance plan helps customer...  \n",
              "4  have known hirani for yrs what if metoo claims...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ca0c972-74e1-46c8-9a83-0863f0261664\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headlines</th>\n",
              "      <th>text</th>\n",
              "      <th>decoder_input</th>\n",
              "      <th>decoder_target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>upgrad learner switches to career in ml al wit...</td>\n",
              "      <td>saurav kant alumnus upgrad iiit pg program mac...</td>\n",
              "      <td>sostoken upgrad learner switches to career in ...</td>\n",
              "      <td>upgrad learner switches to career in ml al wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>delhi techie wins free food from swiggy for on...</td>\n",
              "      <td>kunal shah credit card bill payment platform c...</td>\n",
              "      <td>sostoken delhi techie wins free food from swig...</td>\n",
              "      <td>delhi techie wins free food from swiggy for on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>new zealand end rohit sharma led india match w...</td>\n",
              "      <td>new zealand defeated india wickets fourth odi ...</td>\n",
              "      <td>sostoken new zealand end rohit sharma led indi...</td>\n",
              "      <td>new zealand end rohit sharma led india match w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aegon life iterm insurance plan helps customer...</td>\n",
              "      <td>aegon life iterm insurance plan customers enjo...</td>\n",
              "      <td>sostoken aegon life iterm insurance plan helps...</td>\n",
              "      <td>aegon life iterm insurance plan helps customer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>have known hirani for yrs what if metoo claims...</td>\n",
              "      <td>speaking sexual harassment allegations rajkuma...</td>\n",
              "      <td>sostoken have known hirani for yrs what if met...</td>\n",
              "      <td>have known hirani for yrs what if metoo claims...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ca0c972-74e1-46c8-9a83-0863f0261664')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ca0c972-74e1-46c8-9a83-0863f0261664 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ca0c972-74e1-46c8-9a83-0863f0261664');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "decord의 headlines의 앞에 sostoken이 붙은 input과 뒤에 eostoken이 붙은 target이 생긴것을 확인했다. 이 값들을 다시 NUMPY 타입으로 저장해주자.\n",
        "\n",
        "---\n",
        "\n",
        "아.... years의 줄임말인 yrs가 눈에 띈다.... 누네띠네... 요약문에 큰 영향을 주진 않을 것 같아 그냥 넘어가기로한다....    \n",
        "(아니 한번 처리했는데도 안없어지네...?)\n",
        "어떻게하면 미리 저런 데이터를 처리해서 시간단축을 시킬 수 있을까?  \n"
      ],
      "metadata": {
        "id": "EgyVVr5S0OrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = np.array(data['text']) # 인코더의 입력\n",
        "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
        "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블\n",
        "print('인코더/디코더 레이블 입력 완료:)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWm7kCXrz5cu",
        "outputId": "15143cf4-8924-41ec-f3bb-b77053cc14fe"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인코더/디코더 레이블 입력 완료:)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 trainning/validation 데이터를 나누자.   \n",
        "sklearn을 사용해서 분리해보고 싶었는데, 나눠야할 게 3가지가 되니 조금 머리가 아파 그냥 mix 정수 시퀀스를 만들어서 나눠주자.\n"
      ],
      "metadata": {
        "id": "83MvyTlG20b6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "indices = np.arange(encoder_input.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "print(indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdkBOdNE3nzg",
        "outputId": "f834d0ce-b65d-456d-da32-5810db586cc0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[91559 63077 22940 ... 91810 21864 65455]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = encoder_input[indices]\n",
        "decoder_input = decoder_input[indices]\n",
        "decoder_target = decoder_target[indices]\n",
        "print('random 샘플 정의 완료:)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHIKIdMK2zNv",
        "outputId": "852b33d6-67b5-46d4-9418-1d018bded859"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "random 샘플 정의 완료:)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 섞인 데이터를 8:2의 비율로 train, test로 나눠준다"
      ],
      "metadata": {
        "id": "Lub7jZCx5tLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_of_val = int(len(encoder_input)*0.2)\n",
        "print('테스트 데이터의 수 :',n_of_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7ad66An5juQ",
        "outputId": "697e4f18-56b0-4dbe-b6e6-26ef88088ff6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터의 수 : 19645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_train = encoder_input[:-n_of_val]\n",
        "decoder_input_train = decoder_input[:-n_of_val]\n",
        "decoder_target_train = decoder_target[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input[-n_of_val:]\n",
        "decoder_input_test = decoder_input[-n_of_val:]\n",
        "decoder_target_test = decoder_target[-n_of_val:]\n",
        "\n",
        "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
        "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
        "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
        "print('테스트 레이블의 개수 :', len(decoder_input_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBCxy8Ro5yZl",
        "outputId": "61398be3-d2f8-484d-c21f-fb610e514fc5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터의 개수 : 78580\n",
            "훈련 레이블의 개수 : 78580\n",
            "테스트 데이터의 개수 : 19645\n",
            "테스트 레이블의 개수 : 19645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "encorder/decorder의 input/target 데이터가 잘 나눠진 것을 볼 수 있다. \n",
        "\n",
        "이제 vocab 생성 및 정수 인코딩을 진행하자. "
      ],
      "metadata": {
        "id": "5FoaCCjp5_5l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) 정수 인코딩"
      ],
      "metadata": {
        "id": "Vbw0mkHp6Npd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 단어 집합(vocabulary) 만들기 및 정수 인코딩\n",
        "---\n",
        "이제 encorder/decorder의 input/target으로 나눠진 묶음에 대해 vocab을 생성하자 "
      ],
      "metadata": {
        "id": "CegQx1Bu62sF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
        "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성\n",
        "print('enc_input_train 토크나이저 끝:)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SI_ITvh53zf",
        "outputId": "f2e39542-6131-4b66-ece9-38e78132ebef"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enc_input_train 토크나이저 끝:)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기서 빈도수가 낮은 단어들은 훈련데이터에서 제외해 속도 및 정확도를 올려주자"
      ],
      "metadata": {
        "id": "hKBGkmiO7M30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 7\n",
        "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in src_tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QozNvexa7Kzp",
        "outputId": "d15815f4-c438-407f-96bc-b0281aad3058"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합(vocabulary)의 크기 : 69705\n",
            "등장 빈도가 6번 이하인 희귀 단어의 수: 47538\n",
            "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 22167\n",
            "단어 집합에서 희귀 단어의 비율: 68.19883795997418\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.4886731063047884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "약 7만개의 단어 중 47,000여개의 단어(전체 중 68%)가 4%내의 빈도로 등장하여, 상대적으로 적은 빈도의 단어들이 큰 수를 차지하고 있는 것을 알 수 있다.  \n",
        "따라서 등장 빈도가 7 이하인 단어를 제거해서 vocab의 수를 약 22,000으로 설정하겠습니다.  \n",
        "(지난 실습을 진행해보니 vocab의 수를 무조건 크게 잡는게 좋은게 아니라는 것을 알았다...!)"
      ],
      "metadata": {
        "id": "l346zKsL7eA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab = 22000\n",
        "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
        "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성\n",
        "print('vocab 재설정 완료:)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blW5VH3o7T0t",
        "outputId": "1a9d5a0a-7478-46d2-828d-d9e02e652696"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab 재설정 완료:)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
        "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
        "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
        "\n",
        "# 잘 진행되었는지 샘플 출력\n",
        "print(encoder_input_train[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSSP3uEb8XcB",
        "outputId": "bc668041-4db7-4f87-8692-0cad45cf1e8b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[128, 31, 50, 1180, 142, 3047, 180, 366, 9130, 4729, 944, 501, 637, 18, 741, 42, 140, 192, 50, 8978, 3537, 369, 2179, 77, 239, 697, 73, 818, 1294, 1415, 142, 1339, 142, 1127, 4730, 10271, 9130, 11561], [919, 604, 580, 118, 2649, 172, 10064, 920, 11269, 1117, 2266, 2, 263, 534, 2548, 953, 19, 196, 5444, 2019, 2266, 66, 10, 919, 3885, 14279, 1416, 2233, 2019, 4448, 607, 2292, 8829, 8979], [9, 452, 3071, 228, 105, 824, 370, 26, 9, 701, 91, 45, 761, 195, 660, 3489, 974, 415, 308, 7576, 1115, 1, 3517, 269, 788, 797, 1165, 91, 5944, 55, 1169, 8677, 5718, 10730]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 encoder의 input 데이터들이 22,000 이하의 정수들로 바뀐것을 확인할 수 있다.   \n",
        "headlines의 데이터도 처리해주자"
      ],
      "metadata": {
        "id": "32uaUR1m8d8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tar_tokenizer = Tokenizer()\n",
        "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
        "print('Summary 단어집 생성완료:)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAks7KZ_8c4n",
        "outputId": "c6a36aed-b4db-44d9-c4fa-197e32a56119"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary 단어집 생성완료:)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 6\n",
        "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in tar_tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmyELsUd80PL",
        "outputId": "33e41b1c-3070-4ee0-c67d-d1793c929d6e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합(vocabulary)의 크기 : 30143\n",
            "등장 빈도가 5번 이하인 희귀 단어의 수: 19712\n",
            "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 10431\n",
            "단어 집합에서 희귀 단어의 비율: 65.39495073483064\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 4.640606075586425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "headlines의 경우 5번 이하의 희귀단어가 약 19,000로 65%의 크기를 차지하는 반면, 등장은 5% 내 밖에 되지 않는 것을 알 수 있다.  \n",
        "\n",
        "따라서 단어집의 크기를 깔끔하게 10,000개로 잡아주자"
      ],
      "metadata": {
        "id": "pEMNZY-186Aa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tar_vocab = 10000\n",
        "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
        "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
        "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
        "\n",
        "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
        "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
        "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
        "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
        "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
        "\n",
        "# 잘 변환되었는지 확인\n",
        "print('input')\n",
        "print('input ',decoder_input_train[:10])\n",
        "print('target')\n",
        "print('target ',decoder_target_train[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_Mw96y_82JW",
        "outputId": "06d7fcd4-22de-4080-dfed-f812f55826af"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input\n",
            "input  [[1, 486, 604, 54, 206, 3, 8170, 7206, 2862, 34], [1, 1006, 5893, 1770, 5412, 6, 774, 28, 229], [1, 142, 1745, 27, 66, 668, 7, 4125, 329], [1, 39, 174, 4855, 530, 981, 279, 5, 10, 105, 714], [1, 62, 26, 56, 307, 1619, 3251, 165, 754, 245, 9, 5413], [1, 1062, 380, 873, 3, 927, 415, 438, 7, 441], [1, 1565, 23, 721, 3, 344, 338, 175, 3, 44, 70, 35], [1, 150, 3017, 67, 1103, 71], [1, 372, 1104, 593, 1720, 5202, 6827], [1, 4856, 98, 7207, 180, 241, 7, 29, 684]]\n",
            "target\n",
            "target  [[486, 604, 54, 206, 3, 8170, 7206, 2862, 34, 2], [1006, 5893, 1770, 5412, 6, 774, 28, 229, 2], [142, 1745, 27, 66, 668, 7, 4125, 329, 2], [39, 174, 4855, 530, 981, 279, 5, 10, 105, 714, 2], [62, 26, 56, 307, 1619, 3251, 165, 754, 245, 9, 5413, 2], [1062, 380, 873, 3, 927, 415, 438, 7, 441, 2], [1565, 23, 721, 3, 344, 338, 175, 3, 44, 70, 35, 2], [150, 3017, 67, 1103, 71, 2], [372, 1104, 593, 1720, 5202, 6827, 2], [4856, 98, 7207, 180, 241, 7, 29, 684, 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이렇게 삭제하고 나면, 데이터 내에서 빈도수가 낮은 단어들만으로 구성된 샘플들은 빈값으로 남아있을 가능성이 있다.  \n",
        "혹시 모를 가능성을 없애기위해 빈 데이터들을 찾아 삭제해주자"
      ],
      "metadata": {
        "id": "z2KpqPf59sTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
        "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
        "\n",
        "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
        "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
        "\n",
        "encoder_input_train = [sentence for index, sentence in enumerate(encoder_input_train) if index not in drop_train]\n",
        "decoder_input_train = [sentence for index, sentence in enumerate(decoder_input_train) if index not in drop_train]\n",
        "decoder_target_train = [sentence for index, sentence in enumerate(decoder_target_train) if index not in drop_train]\n",
        "\n",
        "encoder_input_test = [sentence for index, sentence in enumerate(encoder_input_test) if index not in drop_test]\n",
        "decoder_input_test = [sentence for index, sentence in enumerate(decoder_input_test) if index not in drop_test]\n",
        "decoder_target_test = [sentence for index, sentence in enumerate(decoder_target_test) if index not in drop_test]\n",
        "\n",
        "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
        "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
        "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
        "print('테스트 레이블의 개수 :', len(decoder_input_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vC3fK6w9NgH",
        "outputId": "f4176f2d-1949-456b-e361-82593619fb83"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "삭제할 훈련 데이터의 개수 : 0\n",
            "삭제할 테스트 데이터의 개수 : 0\n",
            "훈련 데이터의 개수 : 78580\n",
            "훈련 레이블의 개수 : 78580\n",
            "테스트 데이터의 개수 : 19645\n",
            "테스트 레이블의 개수 : 19645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "뉴스와 헤드라인이라 그런지 빈도수가 낮은 데이터들도 이뤄진 것은 없는 것 같다.  \n",
        "이제 패딩까지 처리하고 모델설계로 넘어가자!"
      ],
      "metadata": {
        "id": "EUSR0C3B98r0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 패딩하기"
      ],
      "metadata": {
        "id": "pIIwHFWt-eiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
        "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
        "decoder_input_train = pad_sequences(decoder_input_train, maxlen=headlines_max_len, padding='post')\n",
        "decoder_target_train = pad_sequences(decoder_target_train, maxlen=headlines_max_len, padding='post')\n",
        "decoder_input_test = pad_sequences(decoder_input_test, maxlen=headlines_max_len, padding='post')\n",
        "decoder_target_test = pad_sequences(decoder_target_test, maxlen=headlines_max_len, padding='post')\n",
        "print('패딩 완료:)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AZCIsCF975M",
        "outputId": "15ebb3c6-95ee-48de-b059-aa06131e7351"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "패딩 완료:)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 모델 설계하기"
      ],
      "metadata": {
        "id": "DpBHqBsg-idq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "지난번 가사추출 AI 설계시 2만개의 단어에서 embedding size를 256으로 진행하니 적절했던게 생각나서 embedding size를 256, hidden size를 512로 해줘보자. "
      ],
      "metadata": {
        "id": "qn-Ofcl7-tTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더 설계 시작\n",
        "embedding_dim = 256\n",
        "hidden_size = 512\n",
        "\n",
        "# 인코더\n",
        "encoder_inputs = Input(shape=(text_max_len,))\n",
        "\n",
        "# 인코더의 임베딩 층\n",
        "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
        "\n",
        "# 인코더의 LSTM 1\n",
        "# encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
        "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "# 인코더의 LSTM 2\n",
        "# encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
        "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "# 인코더의 LSTM 3\n",
        "# encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
        "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
      ],
      "metadata": {
        "id": "IG7x-ntV-hGR"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "일반적인 dropout은 레이어의 weight를 랜덤으로 생략하여 모델의 과적합(overfitting)을 해결해주는 방법이다.\n",
        "\n",
        "반면 recurrent dropout은 dropout을 레이어가 아닌 time step마다 해주는 방식이다. 즉 time step의 입력을 랜덤으로 생략해 주는 것. recurrent dropout은 일반적인 dropout와 같이 regularization을 해주는 효과가 있고, 과적합을 방지할 수 있다고 하니 적용해본다."
      ],
      "metadata": {
        "id": "AJL1AM1gC7Yd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 디코더 설계\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "# 디코더의 임베딩 층\n",
        "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# 디코더의 LSTM\n",
        "# decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
        "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])"
      ],
      "metadata": {
        "id": "gA4OXjFuB_iy"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 디코더의 출력층\n",
        "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
        "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
        "\n",
        "# 모델 정의\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUe0oPEFDIbm",
        "outputId": "8f9873e4-0be6-455c-af0b-104fe2ad718d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 50)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 50, 256)      5632000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 50, 512),    1574912     ['embedding[0][0]']              \n",
            "                                 (None, 512),                                                     \n",
            "                                 (None, 512)]                                                     \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, 50, 512),    2099200     ['lstm[0][0]']                   \n",
            "                                 (None, 512),                                                     \n",
            "                                 (None, 512)]                                                     \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 256)    2560000     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, 50, 512),    2099200     ['lstm_1[0][0]']                 \n",
            "                                 (None, 512),                                                     \n",
            "                                 (None, 512)]                                                     \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 512),  1574912     ['embedding_1[0][0]',            \n",
            "                                 (None, 512),                     'lstm_2[0][1]',                 \n",
            "                                 (None, 512)]                     'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 10000)  5130000     ['lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 20,670,224\n",
            "Trainable params: 20,670,224\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 어텐션 메커니즘"
      ],
      "metadata": {
        "id": "n2UTpXyMVYGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 어텐션 층(어텐션 함수)\n",
        "attn_layer = AdditiveAttention(name='attention_layer')\n",
        "\n",
        "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
        "attn_out = attn_layer([decoder_outputs, encoder_outputs])\n",
        "\n",
        "\n",
        "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "# 디코더의 출력층\n",
        "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
        "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
        "\n",
        "# 모델 정의\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lREG9OXEVbom",
        "outputId": "abc52925-1280-4b81-851b-7c999987198f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 50)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 50, 256)      5632000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 50, 512),    1574912     ['embedding[0][0]']              \n",
            "                                 (None, 512),                                                     \n",
            "                                 (None, 512)]                                                     \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, 50, 512),    2099200     ['lstm[0][0]']                   \n",
            "                                 (None, 512),                                                     \n",
            "                                 (None, 512)]                                                     \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 256)    2560000     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, 50, 512),    2099200     ['lstm_1[0][0]']                 \n",
            "                                 (None, 512),                                                     \n",
            "                                 (None, 512)]                                                     \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 512),  1574912     ['embedding_1[0][0]',            \n",
            "                                 (None, 512),                     'lstm_2[0][1]',                 \n",
            "                                 (None, 512)]                     'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " attention_layer (AdditiveAtten  (None, None, 512)   512         ['lstm_3[0][0]',                 \n",
            " tion)                                                            'lstm_2[0][0]']                 \n",
            "                                                                                                  \n",
            " concat_layer (Concatenate)     (None, None, 1024)   0           ['lstm_3[0][0]',                 \n",
            "                                                                  'attention_layer[0][0]']        \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, None, 10000)  10250000    ['concat_layer[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 25,790,736\n",
            "Trainable params: 25,790,736\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 모델 훈련하기\n",
        "\n",
        "---\n",
        "\n",
        "설계한 모델을 가지고 훈련을 진행해보자.  \n",
        "\n",
        "- 우선 optimizer를 이론때 사용했던 **rmsprop를 사용**\n",
        "- 2017년도 자료이긴하나, **NLP에서 ADAM이 넓게 사용되고 연구자들이 많이 쓴다고**하니, **Adam으로 바꿔서 진행**해볼 예정 [\n",
        "Deep Learning for NLP Best Practices](https://ruder.io/deep-learning-nlp-best-practices/)  \n",
        "(TensorFlow 공식 attention 관련 페이지에도 Adam을 사용했다.)   \n",
        "    + [tf Neural machine translation with attention](https://www.tensorflow.org/text/tutorials/nmt_with_attention)"
      ],
      "metadata": {
        "id": "bx7C6_IuFz3E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5-1) Optimizer rmsprop 사용"
      ],
      "metadata": {
        "id": "5lgMiVjLLj6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
        "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
        "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
        "          batch_size=256, callbacks=[es], epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ2icbY9DKBD",
        "outputId": "59791f51-10ad-400d-86bd-60d59d5bdcd7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "307/307 [==============================] - 64s 175ms/step - loss: 4.7667 - val_loss: 4.3112\n",
            "Epoch 2/50\n",
            "307/307 [==============================] - 53s 171ms/step - loss: 4.1165 - val_loss: 3.8749\n",
            "Epoch 3/50\n",
            "307/307 [==============================] - 52s 171ms/step - loss: 3.7290 - val_loss: 3.6065\n",
            "Epoch 4/50\n",
            "307/307 [==============================] - 52s 171ms/step - loss: 3.4425 - val_loss: 3.4498\n",
            "Epoch 5/50\n",
            "307/307 [==============================] - 52s 171ms/step - loss: 3.2168 - val_loss: 3.3176\n",
            "Epoch 6/50\n",
            "307/307 [==============================] - 53s 171ms/step - loss: 3.0282 - val_loss: 3.2353\n",
            "Epoch 7/50\n",
            "307/307 [==============================] - 53s 171ms/step - loss: 2.8662 - val_loss: 3.1833\n",
            "Epoch 8/50\n",
            "307/307 [==============================] - 52s 171ms/step - loss: 2.7224 - val_loss: 3.1381\n",
            "Epoch 9/50\n",
            "307/307 [==============================] - 53s 171ms/step - loss: 2.5925 - val_loss: 3.1138\n",
            "Epoch 10/50\n",
            "307/307 [==============================] - 53s 171ms/step - loss: 2.4762 - val_loss: 3.1004\n",
            "Epoch 11/50\n",
            "307/307 [==============================] - 53s 171ms/step - loss: 2.3697 - val_loss: 3.0967\n",
            "Epoch 12/50\n",
            "307/307 [==============================] - 52s 171ms/step - loss: 2.2694 - val_loss: 3.0892\n",
            "Epoch 13/50\n",
            "307/307 [==============================] - 52s 171ms/step - loss: 2.1785 - val_loss: 3.0930\n",
            "Epoch 14/50\n",
            "307/307 [==============================] - 53s 171ms/step - loss: 2.0916 - val_loss: 3.1024\n",
            "Epoch 14: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#시각화 하기\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='validation')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "oDuYvFkLGCj9",
        "outputId": "a8fa37db-bfaf-453a-9aa5-a0ef455f1f7d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "train의 loss값이 2.0, val loss값이 3.0으로 생각보다 낮은 수치를 띄고 있는 것 같으니 한번 headlines을 뽑아보자."
      ],
      "metadata": {
        "id": "ev6JIXUPLr6O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 인퍼런스 모델 구현하기"
      ],
      "metadata": {
        "id": "e6QzQZKYMWig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
        "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
        "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음\n",
        "\n",
        "print('인퍼런스 구축완료:)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JovhzkcLafF",
        "outputId": "71855669-12e4-4459-b95c-3c952fa7d8e2"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인퍼런스 구축완료:)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "인코더 모델 설계 "
      ],
      "metadata": {
        "id": "1oB4zMITM5eQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더 설계\n",
        "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# 이전 시점의 상태들을 저장하는 텐서\n",
        "decoder_state_input_h = Input(shape=(hidden_size,))\n",
        "decoder_state_input_c = Input(shape=(hidden_size,))\n",
        "\n",
        "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
        "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "print('인코더 모델 설계 완료')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgImjVi_M0ID",
        "outputId": "a33f128a-ef2a-4eca-b636-3898780e8bdb"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인코더 모델 설계 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "디코더 출력층 설계"
      ],
      "metadata": {
        "id": "pazFzzfnM-kQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 어텐션 함수\n",
        "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
        "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# 디코더의 출력층\n",
        "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
        "\n",
        "# 최종 디코더 모델\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])\n",
        "\n",
        "print('최종 디코더 모델 출력층 설계 완료')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-c_gOB0M9Y7",
        "outputId": "b1eccd01-63e7-4bf6-f722-486d34598299"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최종 디코더 모델 출력층 설계 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # 입력으로부터 인코더의 상태를 얻음\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "     # <SOS>에 해당하는 토큰 생성\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
        "\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = tar_index_to_word[sampled_token_index]\n",
        "\n",
        "        if (sampled_token!='eostoken'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
        "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (headlines_max_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # 상태를 업데이트 합니다.\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence\n",
        "print('디코더 시퀀스 생성!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCjbHgLaNEBK",
        "outputId": "19985edc-b344-4606-d6d1-42bed8616e9d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "디코더 시퀀스 생성!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 모델 테스트하기"
      ],
      "metadata": {
        "id": "nkthbHqHZs79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq2text(input_seq):\n",
        "    temp=''\n",
        "    for i in input_seq:\n",
        "        if (i!=0):\n",
        "            temp = temp + src_index_to_word[i]+' '\n",
        "    return temp\n",
        "\n",
        "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq2summary(input_seq):\n",
        "    temp=''\n",
        "    for i in input_seq:\n",
        "        if ((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
        "            temp = temp + tar_index_to_word[i] + ' '\n",
        "    return temp\n",
        "\n",
        "print('정수 -> 텍스트 시퀀스 생성:)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YG_Ar-ZSZjvj",
        "outputId": "525f990c-5c4d-465a-d3d9-6470b4131792"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정수 -> 텍스트 시퀀스 생성:)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "약 10개 정도 샘플 뽑아서 요약 비교해보자"
      ],
      "metadata": {
        "id": "WL6_xUfPZ4Uc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, 10):\n",
        "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
        "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
        "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS2OtzeQZ2be",
        "outputId": "0710933e-8008-4ae8-8b1c-65a011a49703"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원문 : pakistan pm shahid khaqan abbasi underwent security check us airport last month said check reduce respect prime minister instead increased adding law everyone abbasi said even seen former us president bill clinton go security checks \n",
            "실제 요약 : us airport security check increased my respect pakistan pm \n",
            "예측 요약 :  pakistan pm imran khan not to go on us pm imran khan\n",
            "\n",
            "\n",
            "원문 : delhi police saturday informed total challans issued november signature bridge opened public use november stated challans riding without helmets improper parking one way violation triple riding speeding among others \n",
            "실제 요약 : issued at signature bridge in days of opening \n",
            "예측 요약 :  delhi police to get new year old in delhi\n",
            "\n",
            "\n",
            "원문 : ekta kapoor announced production house balaji motion pictures producing film amul founder kurien known india film directed toilet ek prem katha director shree narayan singh adaptation book dream life kurien \n",
            "실제 요약 : ekta kapoor to produce film on amul founder \n",
            "예측 요약 :  ekta kapoor to feature in hindi film on the year\n",
            "\n",
            "\n",
            "원문 : reserve bank india panel reportedly decided remove bank india bank maharashtra prompt corrective action framework move follows improvements asset quality capital ratios banks reports added state run banks high levels bad debt inadequate capital brought framework \n",
            "실제 요약 : rbi removes two banks from action list reports \n",
            "예측 요약 :  rbi refuses to resolve payment of all of new notes\n",
            "\n",
            "\n",
            "원문 : former indian cricketer virender sehwag took twitter wish former captain sunil gavaskar occasion th birthday calling latter truly today sunny side man taught high confidence generation band india bano wrote notably gavaskar first batsman reach test runs \n",
            "실제 요약 : today sunny side up sehwag wishes truly gavaskar \n",
            "예측 요약 :  sehwag wishes sunil grover on his th birthday\n",
            "\n",
            "\n",
            "원문 : maharashtra government decided hold talks representatives central unions proposed amendment industrial disputes act facilitates closure factories firing workers comes government faced criticism proposing amendment allowing factories less workers close business without prior permission \n",
            "실제 요약 : maha govt calls workers unions to discuss worker law \n",
            "예측 요약 :  maharashtra govt plans to pay leave to employees\n",
            "\n",
            "\n",
            "원문 : inspired unpredictable natural stones titan launches latest collection watches women campaign featuring crystals range watches promise reflect confidence woman flaws pride \n",
            "실제 요약 : titan launches new collection of watches for women \n",
            "예측 요약 :  new zealand is the most beautiful women in the world\n",
            "\n",
            "\n",
            "원문 : american woman born rare disorder wore golden prosthetic arm wedding day marine said whole point wearing draw attention marine usually wears black prosthetic arm year old model worked brands like tommy \n",
            "실제 요약 : woman wears golden arm on wedding day \n",
            "예측 요약 :  woman wears wedding ring wears wears for\n",
            "\n",
            "\n",
            "원문 : tata sons board reportedly rejected proposal tata global beverages purchase mumbai based prabhat dairy crore board consider proposal significant enough wanted tata beverage segment focus core business reports added following shares prabhat dairy plunged much monday \n",
            "실제 요약 : tata sons rejects cr bid to buy dairy reports \n",
            "예측 요약 :  tata sons will be paid by mistry mistry on mistry mistry\n",
            "\n",
            "\n",
            "원문 : unique identification authority india said nris required link bank accounts services aadhaar explained aadhaar meant eligible enrol nris eligible body instructed implementation agencies work mechanisms verify status individuals \n",
            "실제 요약 : nris not required to link bank account with aadhaar \n",
            "예측 요약 :  uidai to link aadhaar aadhaar cards for aadhaar\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "그나마 나은 문장이 'new zealand is the most beautiful women in the world' 이라니요....  \n",
        "문장들이 전부 어색하다....\n",
        "\n",
        "Optimizer를 Adam으로 변경해서 다시 진행해보자....  \n",
        "이것도 안되다면 embedding size를 줄여 더 확실하게 학습시키자...!"
      ],
      "metadata": {
        "id": "h0Qe5Ro-anHD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5-2) Optimizer Adam 사용"
      ],
      "metadata": {
        "id": "Ol_0NPSUaxuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy')\n",
        "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
        "history_2 = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
        "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
        "          batch_size=256, callbacks=[es], epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVWdja48Z9l0",
        "outputId": "e1b42749-3bbb-42eb-d745-193729f03fc7"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "307/307 [==============================] - 59s 174ms/step - loss: 0.9979 - val_loss: 3.5219\n",
            "Epoch 2/50\n",
            "307/307 [==============================] - 52s 170ms/step - loss: 0.9430 - val_loss: 3.5740\n",
            "Epoch 3/50\n",
            "307/307 [==============================] - 52s 170ms/step - loss: 0.9041 - val_loss: 3.6169\n",
            "Epoch 3: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#시각화 하기\n",
        "plt.plot(history_2.history['loss'], label='train')\n",
        "plt.plot(history_2.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "CLjgZPpta3yX",
        "outputId": "cde30515-2ed5-4e4a-9d25-fd88ff0e9125"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "와우 dropout을 시키고 Adam을 썼는데도 과적합이 나온다고요...?   \n",
        "예상도 못한 몹시 당황스러운 결과다...  \n",
        "\n",
        "우선 모델을 돌렸으니 테스트를 시켜보자"
      ],
      "metadata": {
        "id": "I99yiExyTE6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 모델 테스트하기"
      ],
      "metadata": {
        "id": "8R4Z9b_AbJya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, 10):\n",
        "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
        "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
        "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "pPVgPB9abKE4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a22f43d-fe45-4d85-f1ec-23b8599aee6d"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원문 : pakistan pm shahid khaqan abbasi underwent security check us airport last month said check reduce respect prime minister instead increased adding law everyone abbasi said even seen former us president bill clinton go security checks \n",
            "실제 요약 : us airport security check increased my respect pakistan pm \n",
            "예측 요약 :  pak pm imran khan not to stop terrorism says pm abbasi\n",
            "\n",
            "\n",
            "원문 : delhi police saturday informed total challans issued november signature bridge opened public use november stated challans riding without helmets improper parking one way violation triple riding speeding among others \n",
            "실제 요약 : issued at signature bridge in days of opening \n",
            "예측 요약 :  delhi police to get three public bag for people\n",
            "\n",
            "\n",
            "원문 : ekta kapoor announced production house balaji motion pictures producing film amul founder kurien known india film directed toilet ek prem katha director shree narayan singh adaptation book dream life kurien \n",
            "실제 요약 : ekta kapoor to produce film on amul founder \n",
            "예측 요약 :  vaani kapoor to produce web version on report\n",
            "\n",
            "\n",
            "원문 : reserve bank india panel reportedly decided remove bank india bank maharashtra prompt corrective action framework move follows improvements asset quality capital ratios banks reports added state run banks high levels bad debt inadequate capital brought framework \n",
            "실제 요약 : rbi removes two banks from action list reports \n",
            "예측 요약 :  rbi to introduce new payment of banks\n",
            "\n",
            "\n",
            "원문 : former indian cricketer virender sehwag took twitter wish former captain sunil gavaskar occasion th birthday calling latter truly today sunny side man taught high confidence generation band india bano wrote notably gavaskar first batsman reach test runs \n",
            "실제 요약 : today sunny side up sehwag wishes truly gavaskar \n",
            "예측 요약 :  sehwag wishes zaheer on his birthday\n",
            "\n",
            "\n",
            "원문 : maharashtra government decided hold talks representatives central unions proposed amendment industrial disputes act facilitates closure factories firing workers comes government faced criticism proposing amendment allowing factories less workers close business without prior permission \n",
            "실제 요약 : maha govt calls workers unions to discuss worker law \n",
            "예측 요약 :  maha govt to give more interest on planting planting\n",
            "\n",
            "\n",
            "원문 : inspired unpredictable natural stones titan launches latest collection watches women campaign featuring crystals range watches promise reflect confidence woman flaws pride \n",
            "실제 요약 : titan launches new collection of watches for women \n",
            "예측 요약 :  why is the new women behind the universe\n",
            "\n",
            "\n",
            "원문 : american woman born rare disorder wore golden prosthetic arm wedding day marine said whole point wearing draw attention marine usually wears black prosthetic arm year old model worked brands like tommy \n",
            "실제 요약 : woman wears golden arm on wedding day \n",
            "예측 요약 :  woman wears wedding ring gives it to look like\n",
            "\n",
            "\n",
            "원문 : tata sons board reportedly rejected proposal tata global beverages purchase mumbai based prabhat dairy crore board consider proposal significant enough wanted tata beverage segment focus core business reports added following shares prabhat dairy plunged much monday \n",
            "실제 요약 : tata sons rejects cr bid to buy dairy reports \n",
            "예측 요약 :  tata sons rejects bid to sell mistry for crore\n",
            "\n",
            "\n",
            "원문 : unique identification authority india said nris required link bank accounts services aadhaar explained aadhaar meant eligible enrol nris eligible body instructed implementation agencies work mechanisms verify status individuals \n",
            "실제 요약 : nris not required to link bank account with aadhaar \n",
            "예측 요약 :  aadhaar not mandatory for aadhaar enrolment uidai\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "역시나 엉망진창이다...  \n",
        "\n",
        "지금 Optimizer를 RMSProp -> Adam(RMSProp + Momentum) 으로 바꿔 진행했으니,  \n",
        "마지막으로 RMSProp + NAG(관성방향으로 움직이고, 그 자리에 스텝계산)인 Nadam을 한번 사용해보고, 이때도 과적합이 일어난다면, Optimizer는 RMSProp으로 고정시키고 Embedding을 조절해보자 "
      ],
      "metadata": {
        "id": "4qhiYo_OUNV9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5-3) Optimizer Nadam 사용"
      ],
      "metadata": {
        "id": "0Bwoj85TV2bk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Nadam"
      ],
      "metadata": {
        "id": "2HdOAdleYxAh"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='Nadam', loss='sparse_categorical_crossentropy')\n",
        "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
        "history_3 = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
        "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
        "          batch_size=256, callbacks=[es], epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "x33N2lNkTtqV",
        "outputId": "ebf8a5de-26c4-4188-a439-4125d8bd8ade"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "307/307 [==============================] - 61s 180ms/step - loss: 1.0744 - val_loss: 3.4310\n",
            "Epoch 2/50\n",
            "307/307 [==============================] - 54s 176ms/step - loss: 1.0147 - val_loss: 3.4848\n",
            "Epoch 3/50\n",
            " 48/307 [===>..........................] - ETA: 41s - loss: 0.8940"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-90f168bb338a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Nadam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_input_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_target_train\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_input_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_target_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m       \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m     \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \"\"\"\n\u001b[1;32m   1222\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#시각화 하기\n",
        "plt.plot(history_3.history['loss'], label='train')\n",
        "plt.plot(history_3.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ydChchPbWOTM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}